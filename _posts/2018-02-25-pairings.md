---
title: Towards better food pairings?
categories:
  - Food
#tags:
#  - 
#  - 
#  - 
---

When it comes to food and cooking, when you need to pair an ingredient to something else
do you listen your heart or do you listen to data?

Many people have tried the latter and approach food pairings in a more scientific way.
One theory claims that two ingredients go well together when they share a high number of 
xxxx molecules, or specific important ones. It is the approach championed by Heston  
and Herve and it . Thanks to it humanity now can enjoy chocolate and blue cheese, and o.
You can read more about it on the delightful [Khymos]().


<figure class="half">
    <img src="/assets/images/pairings/chickenparm.png">
    <img src="/assets/images/pairings/brownie.png">
    <figcaption>Caption describing these two images.</figcaption>
</figure>


Another approach that have been recently explored relies on recipes and techniques borrowed
from natural language processing (NLP). Roughly speaking the idea is to treat lists of ingredients
as bag of words and extract word embeddings. It is expected that similar foods will end up close 
to each other in the latent space.

Are any of these really satisfactory? 
Word embeddings are exciting but usually they tend to predict well know associations or trivial 
ones. (They tend to reinforce frequent pairings in the corpus and so on.)
You can be easily convinced of that by playing for a few minutes with the fantastic [Food2Vec]().
Looking at molecules, without guidance ... only an expert trained and with a lab. 
Moreover available datasets do not contain information on the amount contained in foods.

Can we find a better way to make use both recipe datasets and molecules one?
To answer that question I decided to use two publicly available sources:
- 1M recipe  
- website, which I scraped  . After cleaning I obtained a set of ~300 ingredients characterized
by ~1k molecules in total


<figure class="half">
    <img width="180" src="/assets/images/pairings/n_ingredients.png">
    <img width="200" src="/assets/images/pairings/zipfs.png">
    <figcaption>Caption describing these two images.</figcaption>
</figure>


## Technicalities 

First of all I tried to reproduce the two approaches mentioned above. Comparing number of shared
molecules between to ingredients is trivial, it can be seen as the scalar product in a one hot-encoded space. 
For the word embeddings I used [GenSim](). 

Finally I tried an hybrid approach. The idea is to weight the molecules of each ingredient based on the times
they are shared with other ingredients in a recipe. Hopefully in this way we highlight at the same time
important molecules in food pairings in general, and those peculiar to each ingredient.
To do that I have been inspired by tf-idf. For each food I count how many times each of its molecules is shared with another ingredient in the same recipe
throughout the entire recipe collection. Then I adjust it by the logarithm of the inverse frequency of that molecule.

Pairing is defined as the closest .. rank


<figure >
    <img width="360" src="/assets/images/pairings/fruitPCA.png">
    <figcaption>Caption describing these two images.</figcaption>
</figure>


## Comparison

We are ready to compare pairing suggestions. I will show the best 10 pairings to a certain ingredient for each
method, here are te results for **tomato**:
 
 Weighted    |     | N Molecules |  | Word Embedding |
  ----------- | ---- | ---------- | --- | ----------------- | ----
  olive oil   | 0.96 | tea        | 184 | oregano           | 0.4
  green beans | 0.96 | potato     | 160 | olive oil         | 0.35
  mango       | 0.96 | mango      | 160 | marjoram          | 0.33
  potato      | 0.96 | guava      | 158 | kidney beans      | 0.33
  pepper      | 0.96 | apple      | 158 | olive             | 0.32
  beans       | 0.95 | grape      | 152 | lamb              | 0.3
  olive       | 0.95 | soybean    | 150 | cheese            | 0.3
  plum        | 0.95 | cocoa      | 149 | mozzarella cheese | 0.29
  rice        | 0.95 | chocolate  | 149 | beans             | 0.29
  soybean     | 0.95 | strawberry | 149 | potato            | 0.28


Of course I cheated choosing a good example which shows both strengths and weaknesses of each method.
Word embeddings give only very predictable pairings, which is still valuable but probably not really 
useful if we want to discover some new pairing. Viceversa number of shared molecules ends
up giving interesting pairings but which ones should we trust? 
Weighted vectors give somewhat a combination of the two, apparently promoting tomato-mango as the best 
least expected result. However it completely missed the often quoted similarity between strawberries and tomatoes.

Another interesting example for squid:



squid and cheese!



You can find and explore the complete best 10 results on a CSV file uploaded on my GitHub.
In the same depository there are also the complete vector representations for the three methods
in case anybody wants to play with them, and of course the code I used.
Bon Appetit!
 

## Wishlist

Better molecule dataset
is there any other way of ranking
explore combinatio
app



Now this



## GitHub Repo

Code on my GitHub [repo](https://github.com/roundedup)
