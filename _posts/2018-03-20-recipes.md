---
title: What should I cook for dinner?
categories:
  - Food
#tags:
#  - 
#  - 
#  - 
---

It's time to make dinner. 

Some milk in the fridge, a   .
What can I make 

That's the plan, very simple. Give input a list of ingredients and get back an idea, a dish 
that it could be possibly made with them. Using a generative model we could even find new recipes
never discovered before, it can help up find an application to one of those new food pairings we discovered 
last time.

How do we get there? I decided to code an RNN, with a vector to sequence model, 
. Technically speaking I used as starting point the seq2seq Keras code available here, adapting
parts of it and coding all the necessary additions. The final architecture is relatively simple and
as often a picture is worth a thousand words so here is a cartoon of the network

<figure >
    <img width="320" src="/assets/images/pairings/cartoon.png">
    <figcaption>Unrolled depiction of the RNN, with "chewy chocolate chip cookie" recipe.</figcaption>
</figure>





The input is a list of ingredients in the form of a one hot encoded vector. It is passed through a dense
layer to reduce its dimensionality from ~500 to 32 and used as the initial hidden state of a GRU with softmax activation. 
which takes the title of the recipe as input, trying to predict the title itself (with teacher mode enforced).
The title representation is word level, with an word encoding of ~4000 dimension.
The whole network is trained on a list of almost 200k recipes, that I selected from the MIT recipe dataset after cleaning
the ingredient list, mostly by requiring title length between 3 and 7 words, no uncommon words in the title.

My laptop was really slow so I switched to Amazon Web Services, to do that I mainly followed this two guides.
Training took a few hours for a total of 200 epochs on a p2.xlarge instance.

After training we can generate new recipe titles. Each word is chosen among the top 5 most probable ones predicted 
by the network and used as an input to predict the next one.  

With no further ado here are some results. 
First we can check that conditioning on common ingredient lists returns reasonable titles.
I will use the two examples of the previous post. 



Now we can try something more original, for instance the crab and chocolate combination from earlier.
Here is what my code offers for dinner:



I selected only three but of course there are also disastrous suggestions:





## What's next?

An app online to let everybody enjoy the results.
Expand the code to generate not only titles but whole recipes with instructions if possible.



## GitHub Repo

Code on my GitHub [repo](https://github.com/roundedup)
